{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "herbal-chemical",
   "metadata": {},
   "source": [
    "# Homework 4: Unsupervised Learning\n",
    "Andrew Corum, Brendan Mcshane\n",
    "\n",
    "## Question 1\n",
    "About a week ago, Brendan and I decided how to split up the work (Brendan takes Q1, I answer Q2). \n",
    "\n",
    "On Monday, 4/19, Brendan told me that he was nearly done with Q1. However, I have not heard back from him in the last two days.\n",
    "\n",
    "I didn't complete Q1 by myself because I was under the impression that Brendan would be able to show me his results today. But it seems I am out of time to work on this.\n",
    "\n",
    "I might send you (Dr Willimamson and Junyi) an email to see what I should do. If I could have an extra day to work on the homework, then I would be able to answer Q1 myself and turn in a full assignment. Or is there another solution you can think of? I understand if the deadline needs to stay fixed at 4/21 11:59pm. But, if possible, I would like to avoid getting an unnexpected 50% on this assignment.\n",
    "\n",
    "Sorry for the trouble. This was a very hard issue to forsee since I had communication with Brendan for a while... but then no communication right before the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-musician",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fluid-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# Displaying images\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "speaking-israel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example label: 7\n",
      "Example image:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to load IDX formatted MNIST data from file\n",
    "def load_data(filename, image_data=False):\n",
    "    data = None\n",
    "    file = open(\"./data/\" + filename, \"rb\")\n",
    "    file.read(4) # Ignore magic number\n",
    "    N = int.from_bytes(file.read(4), 'big') # Get number of data points\n",
    "    if image_data:\n",
    "        R = int.from_bytes(file.read(4), 'big') # Get number of rows\n",
    "        C = int.from_bytes(file.read(4), 'big') # Get number of columns\n",
    "        data = np.frombuffer(file.read(N*R*C), dtype=np.uint8)\n",
    "        data = np.reshape(data, (N,R*C))\n",
    "    else:\n",
    "        data = np.frombuffer(file.read(N), dtype=np.uint8)\n",
    "        data = np.reshape(data, (N))\n",
    "    file.close()\n",
    "    return data\n",
    "\n",
    "# Get MNIST data\n",
    "train_images = load_data(\"train-images\", True)\n",
    "train_labels = load_data(\"train-labels\")\n",
    "test_images = load_data(\"test-images\", True)\n",
    "test_labels = load_data(\"test-labels\")\n",
    "\n",
    "# Test that data has been loaded properly\n",
    "print(\"Example label: {}\".format(test_labels[0]))\n",
    "print(\"Example image:\")\n",
    "im = Image.fromarray(test_images[0].reshape(28,28), mode='L')\n",
    "imshow(im);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "leading-president",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, no PCA\n",
      "  Dimension: 784\n",
      "  Time: 34.29003953933716\n",
      "  Accuracy: 0.9705\n",
      "[[ 969    0    0    0    0    2    5    1    3    0]\n",
      " [   0 1124    2    3    0    2    2    1    1    0]\n",
      " [   5    0  999    7    2    0    3    9    7    0]\n",
      " [   1    0   10  971    0   10    0    8    8    2]\n",
      " [   1    0    1    0  958    0    6    0    2   14]\n",
      " [   3    0    0   11    0  862    8    2    4    2]\n",
      " [   6    3    0    0    3    4  939    0    3    0]\n",
      " [   1    3   20    1    0    0    0  989    3   11]\n",
      " [   5    0    5    6    4    9    4    4  928    9]\n",
      " [   8    5    1    9    8    3    1    4    4  966]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF, no PCA\n",
    "# Train RF\n",
    "clf = RandomForestClassifier(max_depth=None, n_estimators=100, random_state=0)\n",
    "t_start = time()\n",
    "clf.fit(train_images, train_labels)\n",
    "t = time() - t_start\n",
    "# Test & evaluate RF\n",
    "labels_pred = clf.predict(test_images)\n",
    "cfn = confusion_matrix(test_labels, labels_pred)\n",
    "acc = accuracy_score(test_labels, labels_pred)\n",
    "dim = test_images[0].size\n",
    "print(\"RF, no PCA\")\n",
    "print(\"  Dimension: {}\\n  Time: {}\\n  Accuracy: {}\".format(dim, t, acc))\n",
    "print(cfn, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "expanded-disorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, PCA (0.95 explained variance ratio)\n",
      "  Dimension: 154\n",
      "  Time: 74.28770208358765\n",
      "  Accuracy: 0.949\n",
      "[[ 964    0    1    0    1    2    8    1    3    0]\n",
      " [   0 1120    3    4    0    2    4    0    2    0]\n",
      " [   8    0  968   12    8    3    3    9   20    1]\n",
      " [   2    1    5  956    1   12    2    9   17    5]\n",
      " [   1    2    7    2  933    1    9    2    2   23]\n",
      " [   2    0    4   30    3  832    8    3    6    4]\n",
      " [   8    4    2    0    3    7  933    0    1    0]\n",
      " [   1    6   20    2   10    0    0  965    1   23]\n",
      " [   6    0   10   18   11   20    4    5  890   10]\n",
      " [   6    5    3   14   26    4    0   12   10  929]] \n",
      "\n",
      "RF, PCA (0.9 explained variance ratio)\n",
      "  Dimension: 87\n",
      "  Time: 54.697843074798584\n",
      "  Accuracy: 0.9528\n",
      "[[ 964    0    3    1    1    4    5    1    1    0]\n",
      " [   0 1120    1    5    0    1    5    0    2    1]\n",
      " [   7    0  973   11    7    0    3    9   22    0]\n",
      " [   3    0    8  954    1   16    0    9   15    4]\n",
      " [   0    1    5    1  938    3    7    1    2   24]\n",
      " [   3    1    3   15    4  845    8    3    4    6]\n",
      " [   7    2    3    0    3    6  936    0    1    0]\n",
      " [   1    4   19    3    6    0    1  976    2   16]\n",
      " [   8    0   11   19    8   19    5    6  890    8]\n",
      " [   7    6    4   13   21    6    0   13    7  932]] \n",
      "\n",
      "RF, PCA (0.85 explained variance ratio)\n",
      "  Dimension: 59\n",
      "  Time: 42.87822866439819\n",
      "  Accuracy: 0.9545\n",
      "[[ 964    0    3    0    0    4    6    2    1    0]\n",
      " [   0 1119    4    4    0    1    4    0    2    1]\n",
      " [   6    0  979    9    5    1    2    9   20    1]\n",
      " [   1    0    7  957    2   14    2    6   17    4]\n",
      " [   1    0    4    0  940    2    8    1    2   24]\n",
      " [   4    1    2   22    6  839    9    1    5    3]\n",
      " [   6    3    1    0    6    4  937    0    1    0]\n",
      " [   2    5   19    2    6    0    0  971    3   20]\n",
      " [   4    0   10   15    9   15    3    5  906    7]\n",
      " [   4    6    3   14   24    7    0   11    7  933]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF, with PCA, varying explained variance ratio\n",
    "for ev in [.95, .9, .85]:\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=ev, svd_solver='full')\n",
    "    train_pca = pca.fit_transform(train_images)\n",
    "    # Train RF\n",
    "    clf = RandomForestClassifier(max_depth=None, n_estimators=100, random_state=0)\n",
    "    t_start = time()\n",
    "    clf.fit(train_pca, train_labels)\n",
    "    t = time() - t_start\n",
    "    # Test & evaluate RF\n",
    "    labels_pred = clf.predict(pca.transform(test_images))\n",
    "    cfn = confusion_matrix(test_labels, labels_pred)\n",
    "    acc = accuracy_score(test_labels, labels_pred)\n",
    "    dim = train_pca[0].size\n",
    "    print(\"RF, PCA ({} explained variance ratio)\".format(ev))\n",
    "    print(\"  Dimension: {}\\n  Time: {}\\n  Accuracy: {}\".format(dim, t, acc))\n",
    "    print(cfn, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-california",
   "metadata": {},
   "source": [
    "PCA reduces the dimension of our data. The input MNIST data contains 28x28 pixel images, so the dimension is 28x28 = 784. This is a very large number of features to include in a model, so it makes sense to use PCA to try to reduce the number of features.\n",
    "\n",
    "With 95% explained variance ratio (EVR), the PCA-reduced data has 154 dimensions. Then reducing further, 90% EVR gives 87 dimensions and 85% EVR reduces to 59 dimensions. Higher EVR means that the PCA-reduced dataset accounts for more of the variance within the original data. But when allowing for lower EVR, we are able to reduce the input dimension even more.\n",
    "\n",
    "Lowering the dimension of the input initially increases random forest (RF) training time. To train on all 60,000 images, it took ~35 seconds. But the initial reduction to 154 dimensions increased training time to ~74 seconds. This is likely because the PCA-reduced data is much less sparce than the original data. Remember, the MNIST data contains handwritten digits, so most of the features take value = 0 (white space). But PCA reduces a lot of these unnecessary features. However, among the PCA-reduced data, the further we reduce the dimension, the further we lower the RF training time.\n",
    "\n",
    "Comparing the No-PCA RF model to the 95%-PCA model, we see that the accuracy drops (97.1% to 94.9%). This is not surprising, as we lose a lot of information when the dimension of the data drops from 784 to 154. However, comparing the PCA models, we actually see an increase in accuracy as the EVR drops. Among the models trained on PCA-reduced data, the 85% EVR result performs best (95.5% accuracy). This can be explaind by the curse of dimensionality, which says that patterns in data often do not appear (or are harding to find) in higher dimensions. \n",
    "\n",
    "**Results:**\n",
    "\n",
    "| **PCA EVR**|**Dim**|**Time**|**Accuracy**|\n",
    "|------------|-----|------|----------|\n",
    "| N/A (1.00) | 784 | 34.3 | 0.971    |\n",
    "| 0.95       | 154 | 74.3 | 0.949    |\n",
    "| 0.90       | 87  | 54.7 | 0.953    |\n",
    "| 0.85       | 59  | 42.9 | 0.955    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-berkeley",
   "metadata": {},
   "source": [
    "## Resources\n",
    "* MNIST dataset: https://deepai.org/dataset/mnist\n",
    "* Reading buffers to numpy arrays: https://stackoverflow.com/questions/47637758/how-can-i-make-a-numpy-ndarray-from-bytes\n",
    "* Jupyter images: https://stackoverflow.com/questions/26649716/how-to-show-pil-image-in-ipython-notebook\n",
    "* Pillow docs: https://pillow.readthedocs.io/en/stable/reference/Image.html\n",
    "* sklearn RF: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "* sklearn confusion matrix: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "* sklearn PCA: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "* sklearn score https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
